# Supervised and Semi-supervised Sentence Encoding Methods for Dialogue Act Classification

# TODO

- models
- Add second dense layer to classification layers??? Time distributed?
- could half units in lstm and train for longer?

- GRU?
- Recurrent convolutional
- rnnlm
- elmo (try 'elmo' instead of default?) + elmo attention? More layers? 
- bert + attention? Different layers? 

- Visualising attention layers
- Save train/test history + predictions?